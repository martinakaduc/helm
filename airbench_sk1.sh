export AZURE_OPENAI_ENDPOINT="https://gpt4o-sv1.openai.azure.com/"
export AZURE_OPENAI_API_KEY="fe7466dce5da443b94dae5f8f9c1081b"

# python run_helm_vllm.py --model Austism/chronos-hermes-13b
# python run_helm_vllm.py --model Gryphe/MythoMax-L2-13b
python run_helm_vllm.py --model NousResearch/Nous-Capybara-7B-V1.9 # No format support # Try again
python run_helm_vllm.py --model NousResearch/Nous-Hermes-2-Mistral-7B-DPO
python run_helm_vllm.py --model NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO
python run_helm_vllm.py --model NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT
python run_helm_vllm.py --model NousResearch/Nous-Hermes-2-Yi-34B
python run_helm_vllm.py --model NousResearch/Nous-Hermes-Llama2-13b
python run_helm_vllm.py --model NousResearch/Nous-Hermes-Llama-2-7b
python run_helm_vllm.py --model Open-Orca/Mistral-7B-OpenOrca
python run_helm_vllm.py --model qwen/qwen1.5-0.5b-chat
python run_helm_vllm.py --model qwen/qwen1.5-1.8b-chat
python run_helm_vllm.py --model qwen/qwen1.5-4b-chat
python run_helm_vllm.py --model qwen/qwen1.5-7b
python run_helm_vllm.py --model qwen/qwen1.5-14b
python run_helm_vllm.py --model qwen/qwen1.5-32b # ht2
python run_helm_vllm.py --model qwen/qwen1.5-110b-chat # ht2
# python run_helm_vllm.py --model snowflake/snowflake-arctic-instruct # sk3
python run_helm_vllm.py --model Undi95/Toppy-M-7B
python run_helm_vllm.py --model WizardLM/WizardLM-13B-V1.2
python run_helm_vllm.py --model codellama/CodeLlama-13b-Instruct-hf
python run_helm_vllm.py --model codellama/CodeLlama-34b-Instruct-hf # sk3
python run_helm_vllm.py --model codellama/CodeLlama-70b-Instruct-hf # sk3
python run_helm_vllm.py --model codellama/CodeLlama-7b-Instruct-hf
python run_helm_vllm.py --model cognitivecomputations/dolphin-2.5-mixtral-8x7b
# python run_helm_vllm.py --model deepseek-ai/deepseek-coder-33b-instruct # sk3
python run_helm_vllm.py --model garage-bAInd/Platypus2-70B-instruct # sk3
python run_helm_vllm.py --model google/gemma-2b-it # ht1
python run_helm_vllm.py --model google/gemma-7b-it # ht1
python run_helm_vllm.py --model lmsys/vicuna-13b-v1.5 # ht1
python run_helm_vllm.py --model lmsys/vicuna-7b-v1.5 # ht1
python run_helm_vllm.py --model meta-llama/Llama-2-13b-chat-hf # ht1
python run_helm_vllm.py --model meta-llama/Llama-2-70b-chat-hf # sk3
python run_helm_vllm.py --model meta-llama/Llama-2-7b-chat-hf
python run_helm_vllm.py --model mistralai/mistral-7b-v0.1
python run_helm_vllm.py --model mistralai/Mistral-7B-Instruct-v0.2
python run_helm_vllm.py --model openchat/openchat-3.5-1210 # ht2
python run_helm_vllm.py --model snorkelai/Snorkel-Mistral-PairRM-DPO
python run_helm_vllm.py --model teknium/OpenHermes-2-Mistral-7B # ht2
python run_helm_vllm.py --model teknium/OpenHermes-2.5-Mistral-7B # ht2
# python run_helm_vllm.py --model togethercomputer/StripedHyena-Nous-7B # ht2
python run_helm_vllm.py --model upstage/SOLAR-10.7B-Instruct-v1.0 # ht2
